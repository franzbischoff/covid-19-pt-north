---
title: "SIR Portugal"
bibliography: references.bib
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/ieee.csl
output: 
  html_notebook: 
    code_folding: hide
    fig_caption: yes
    number_sections: yes
    theme: united
    toc: yes
---

# Concepts

- **Incubation Period**: is the time between infection and the visible appearance of symptoms.
- **Latency period**: is the period of time between infection and the ability to infect
someone.

# Model Hypothesis

## Compartments

The population is assumed to be divided in three groups:

- **Susceptible** individuals
- **Infected**, symptomatic and infectious
- **Recovered**, immune from further infection

## Discrete time

The observations, for simplicity, will be analyzed as a *discrete* time-series.
In this case we will use `days`.

## Constant Population

As a mathematical convenience, the total number of individuals is kept constant. The deaths are included in the *Recovered* group.

## Other assumptions

- The population is considered big, so the random effects can be ignored.
- The population is considered homogeneous at any point in time. This means that the individuals of any compartment are distributed randomically.
- The disease is transmitted by proximity or contact between an infected and a susceptible individual (individual contact model - ICM).
- The susceptible individual becomes infected instantaneously, the latency period is ignored.
- The infected eventually get recovered and become immune.

```{r setup, include=FALSE}
version_date <- lubridate::ymd("2020-03-21")

knitr::opts_chunk$set(
  warnings = TRUE,
  echo = FALSE,
  cache = FALSE,
  prompt = FALSE,
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 60)
)
# Install package if needed
if (!requireNamespace("EpiModel", quietly = TRUE)) {
  devtools::install_github("statnet/EpiModel", quiet = TRUE)
}
if (!requireNamespace("ggridges", quietly = TRUE)) {
  install.packages("ggridges", quiet = TRUE)
}
if (!requireNamespace("incidence", quietly = TRUE)) {
  install.packages("incidence", quiet = TRUE)
}
if (!requireNamespace("sodium", quietly = TRUE)) {
  system("apt install libsodium-dev")
  install.packages("sodium", quiet = TRUE)
}
if (!requireNamespace("epitrix", quietly = TRUE)) {
  install.packages("epitrix", quiet = TRUE)
}
if (!requireNamespace("earlyR", quietly = TRUE)) {
  install.packages("earlyR", quiet = TRUE)
}
if (!requireNamespace("EpiEstim", quietly = TRUE)) {
  install.packages("EpiEstim", quiet = TRUE)
}
if (!requireNamespace("coronavirus", quietly = TRUE)) {
  devtools::install_github("RamiKrispin/coronavirus", quiet = TRUE)
}
if (!requireNamespace("jsonlite", quietly = TRUE)) {
  install.packages("jsonlite", quiet = TRUE)
}
if (!requireNamespace("DiagrammeR", quietly = TRUE)) {
  install.packages("DiagrammeR", quiet = TRUE)
}
if (!requireNamespace("gt", quietly = TRUE)) {
  devtools::install_github("rstudio/gt", quiet = TRUE)
}

# Load EpiModel
suppressMessages(library(EpiModel))
suppressMessages(library(tidyverse))
suppressMessages(library(ggridges))
suppressMessages(library(incidence))
suppressMessages(library(earlyR))
suppressMessages(library(EpiEstim))
suppressMessages(library(coronavirus))
suppressMessages(library(jsonlite))
suppressMessages(library(DiagrammeR))
suppressMessages(library(gt))
library(foreach)
library(parallel)

if (requireNamespace("conflicted", quietly = TRUE)) {
  conflicted::conflict_prefer("lag", "dplyr")
  conflicted::conflict_prefer("filter", "dplyr")
}
```

```{r monkey patch, echo=FALSE}
source_files <- c(
  "_icm.mod.init.seiqhrf.R",
  "_icm.mod.status.seiqhrf.R",
  "_icm.mod.vital.seiqhrf.R",
  "_icm.control.seiqhrf.R",
  "_icm.utils.seiqhrf.R",
  "_icm.saveout.seiqhrf.R",
  "_icm.icm.seiqhrf.R"
)

for (source_file in source_files) {
  source(paste0("./ext/", source_file))
}
```

```{r fetch data, echo=FALSE}
dgs_cases_url <- "https://services.arcgis.com/CCZiGSEQbAxxFVh3/arcgis/rest/services/COVID19Portugal_view/FeatureServer/0/query?f=json&where=1=1&returnGeometry=false&spatialRel=esriSpatialRelIntersects&outFields=*&orderByFields=datarelatorio asc&resultOffset=0&resultRecordCount=1000"
dgs_geo_url <- "https://services.arcgis.com/CCZiGSEQbAxxFVh3/arcgis/rest/services/COVID19Portugal_view/FeatureServer/1/query?f=json&where=1=1&returnGeometry=false&spatialRel=esriSpatialRelIntersects&outFields=*&orderByFields=dist_casosconf desc&resultOffset=0&resultRecordCount=1000"

# dgs_cases <- fromJSON("../data/dgs_cases.json")
dgs_cases <- fromJSON(URLencode(dgs_cases_url))
dgs_geo <- fromJSON(URLencode(dgs_geo_url))
```

```{r general summary, echo=FALSE}
geo_dataset <- dgs_geo[["features"]][["attributes"]]
geo_colnames <- c(
  "id_objeto", "id_global", "data_relatorio", "distrito",
  "casos_confirmados", "n_obitos", "recuperados", "id_global_pai",
  "creation_date", "creator", "edit_date", "editor", "untimo_registo"
)
names(geo_dataset) <- geo_colnames

geo_dataset$data_relatorio <- as.Date(as.POSIXct(geo_dataset$data_relatorio / 1000, origin = "1960-01-01"))
geo_dataset$creation_date <- as.Date(as.POSIXct(geo_dataset$creation_date / 1000, origin = "1960-01-01"))
geo_dataset$edit_date <- as.Date(as.POSIXct(geo_dataset$edit_date / 1000, origin = "1960-01-01"))
geo_norte <- geo_dataset %>%
  filter(distrito == "+041.45756_-007.67865") %>%
  distinct_at(vars(data_relatorio), .keep_all = TRUE) %>%
  arrange(data_relatorio) %>%
  mutate(id_objeto = seq(13, n() + 13 - 1))


cases_dataset <- dgs_cases[["features"]][["attributes"]]
colnames <- c(
  "id_objeto", "id_global", "data_relatorio", "casos_confirmados",
  "n_obitos", "recuperados", "casos_suspeitos", "casos_masculinos",
  "casos_femininos", "gr_etario_0_9", "gr_etario_10_19", "gr_etario_20_29",
  "gr_etario_30_39", "gr_etario_40_49", "gr_etario_50_59", "gr_etario_60_69",
  "gr_etario_70_79", "gr_etario_80_89", "gr_etario_90_99", "casos_importados",
  "casos_contacto", "sintoma_febre", "sintoma_tosse", "sintoma_dores",
  "sintoma_cefaleia", "sintoma_fraqueza", "creation_date", "creator", "edit_date",
  "editor", "casos_novos", "sintoma_difrespiratoria", "ultimo_registo",
  "estrangeiro", "casos_ativos", "aguarda_resultado", "contatos_vigilancia",
  "cadeias_transmissao", "casos_internados", "casos_internados_uci"
)
names(cases_dataset) <- colnames
cases_dataset$data_relatorio <- as.Date(as.POSIXct(cases_dataset$data_relatorio / 1000, origin = "1960-01-01"))
cases_dataset$edit_date <- as.POSIXct(cases_dataset$edit_date / 1000, origin = "1960-01-01")
cases_dataset$creation_date <- as.POSIXct(cases_dataset$creation_date / 1000, origin = "1960-01-01")

# remove rows that have all NA in a selection of columns
cases_dataset <- cases_dataset %>% filter_at(vars(casos_confirmados:sintoma_fraqueza), any_vars(!is.na(.)))

cases_dataset <- cases_dataset %>%
  select(
    id_objeto, data_relatorio, casos_confirmados, casos_novos,
    casos_suspeitos, recuperados, n_obitos, casos_masculinos, casos_femininos,
    casos_importados, casos_contacto, estrangeiro, casos_ativos, aguarda_resultado,
    gr_etario_0_9, gr_etario_10_19, gr_etario_20_29, gr_etario_30_39,
    gr_etario_40_49, gr_etario_50_59, gr_etario_60_69, gr_etario_70_79,
    gr_etario_80_89, gr_etario_90_99, contatos_vigilancia,
    casos_internados, casos_internados_uci, sintoma_febre, sintoma_tosse,
    sintoma_dores, sintoma_cefaleia, sintoma_fraqueza, sintoma_difrespiratoria
  ) %>%
  arrange(data_relatorio) %>%
  distinct_at(vars(data_relatorio:sintoma_difrespiratoria), .keep_all = TRUE) %>%
  mutate(id_objeto = 1:n())
```

```{r check data, echo=FALSE, warning=FALSE}
# check data
by_age <- cases_dataset %>%
  select(starts_with("gr_etario")) %>%
  rowSums(na.rm = T)
by_sex <- cases_dataset$casos_masculinos + cases_dataset$casos_femininos
by_transmission <- cases_dataset$casos_contacto + cases_dataset$casos_importados
by_status <- cases_dataset$recuperados + cases_dataset$n_obitos + cases_dataset$casos_ativos

if (!identical(cases_dataset$casos_confirmados, by_status)) {
  err <- which(cases_dataset$casos_confirmados != by_status)

  for (n in err) {
    cat(paste0(
      "Incongruência no dia ", cases_dataset$data_relatorio[n],
      " Confirmados: ", cases_dataset$casos_confirmados[n],
      ", ativos + obitos+ recuperados: ", by_status[n], "\n"
    ))
  }
}

if (!identical(cases_dataset$casos_confirmados, by_age)) {
  err <- which(cases_dataset$casos_confirmados != by_age)

  for (n in err) {
    cat(paste0(
      "Incongruência no dia ", cases_dataset$data_relatorio[n],
      " Confirmados: ", cases_dataset$casos_confirmados[n],
      ", Soma das faixas etárias: ", by_age[n], "\n"
    ))
  }
}

if (!identical(cases_dataset$casos_confirmados, by_sex)) {
  err <- which(cases_dataset$casos_confirmados != by_sex)

  for (n in err) {
    cat(paste0(
      "Incongruência no dia ", cases_dataset$data_relatorio[n],
      " Confirmados: ", cases_dataset$casos_confirmados[n],
      ", Homens + Mulheres: ", by_sex[n], "\n"
    ))
  }
}

if (!identical(cases_dataset$casos_confirmados, by_transmission)) {
  err <- which(cases_dataset$casos_confirmados != by_transmission)

  for (n in err) {
    cat(paste0(
      "Incongruência no dia ", cases_dataset$data_relatorio[n],
      " Confirmados: ", cases_dataset$casos_confirmados[n],
      ", Contato + Importados: ", by_transmission[n], "\n"
    ))
  }
}

# by_suspicion <- cases_dataset$aguarda_resultado + cases_dataset$casos_confirmados
#
# if (!identical(cases_dataset$casos_suspeitos, by_suspicion)) {
#   err <- which(cases_dataset$casos_suspeitos != by_suspicion)
#
#   for (n in err) {
#     message(
#       "Incongruência no dia ", cases_dataset$data_relatorio[n],
#       " Suspeitos: ", cases_dataset$casos_suspeitos[n],
#       ", Aguarda + Confirmados: ", by_transmission[n]
#     )
#   }
# }
```

# Extended Model

A more complex model is proposed by Churches, T[@churches2020modellingcovid19rpart2] adding several compartments and permit a better exploration of the potential effects of various combinations and timings of interventions on COVID-19 spread.

Attention to the description of each compartment:

| Compartment | Functional definition                                                             |
|-------------|-----------------------------------------------------------------------------------|
| S           | Susceptible individuals                                                           |
| E           | Exposed **and** infected, not yet symptomatic but potentially infectious          |
| I           | Infected, symptomatic **and** infectious                                          |
| Q           | Infectious, but (self-)isolated                                                   |
| H           | Requiring hospitalisation (would normally be hospitalised if capacity available)  |
| R           | Recovered, immune from further infection                                          |
| F           | Case fatality (death due to COVID-19, not other causes)                           |

## Transition diagram

```{r flow chart, echo=FALSE}
grViz("
digraph SEIQHRF {

  # a 'graph' statement
  graph [overlap = false, fontsize = 10] #, rankdir = LR]

  # several 'node' statements
  node [shape = box,
        fontname = Helvetica]
  S[label='S=Susceptible'];
  E[label='E=Exposed and infected,\nasymptomatic,\npotentially infectious'];
  I[label='I=Infected and infectious'];
  Q[label='Q=(Self-)isolated\n(infectious)'];
  H[label='H=Requires\nhospitalisation'];
  R[label='R=Recovered/immune'];
  F[label='F=Case fatality']

  # several 'edge' statements
  S->E[label='a']
  I->S[style='dashed', label='x']
  E->I[label='b']
  E->S[style='dashed', label='y']
  I->Q[label='c']
  Q->S[style='dashed', label='z']
  I->R[label='d']
  I->H[label='e']
  H->F[label='f']
  H->R[label='g']
  Q->R[label='h']
  Q->H[label='i']
}
")
```

## Parameters

There is **a lot** of parameters. We will start with the defaults and adjust accordingly to new evidences.

```{r parameters, echo=FALSE}
param_docs <- tribble(
  ~DiagramRef, ~Parameter, ~Default, ~Explanation,
  "", "type", "SEIQHRF", "Type of model: SI, SIR, SIS, SEIR, SEIQHR and SEIQHRF available, but only SEIQHRF is likely to work in the current version of the code.",

  "", "nsteps", 366, "Number of days for simulation. Note that day 1 is for initialisation, day 2 is the first day of the simulation, hence default of 366 for 1 year.",

  "", "nsims", 10, "Number of simulations to run and then average.",

  "", "ncores", 10, "Number of CPU cores to use for parallel execution.",

  "b", "prog.rand", FALSE, "Method for progression from E compartment to I. If TRUE, random binomial draws at `prog.rate`, if FALSE, random draws from a Weibull distribution (yes, I know it should be a discrete Weibull distribution but it makes little difference and speed of computation matters), with parameters `prog.dist.scale` and  `prog.dist.shape`",

  "d,g,h", "rec.rand", FALSE, "Method for recovery transition from I, Q or H to R. If TRUE, random binomial draws at `rec.rate`, if FALSE, random draws from a random draws from a Weibull distribution, with parameters `rec.dist.scale` and  `rec.dist.shape`",

  "f", "fat.rand", FALSE, "Method for case fatality transition from H to F. If TRUE, random binomial draws at `fat.rate.base`, if FALSE, random sample with a sample fraction also given by `fat.rate.base`. However, if the current number of patients in the H (needs hospitalisation) compartment is above a hospital capacity level specified by `hosp.cap`, then the fatality rate is the mean of the base fatality rate weighted by the hospital capacity, plus a higher rate, specified by `fat.rate.overcap`, weighted by the balance of those requiring hospitalisation (but who can't be accommodated). By setting `fat.rate.overcap` higher, the effect of exceeding the capacity of the health care system can be simulated. There is also a coefficient `fat.tcoeff` for the fatality rates that increases them as a linear function of the number of days the individual has been in the H compartment. Use of the co-efficient better approximates the trapezoid survival time distribution typical of ICU patients.",

  "c", "quar.rand", FALSE, "Method for self-isolation transition from I to Q. If TRUE, random binomial draws at `quar.rate`, if FALSE, random sample with a sample fraction also given by `quar.rate.",

  "e,i", "hosp.rand", FALSE, "Method for transition from I or Q to H -- that is, from infectious or from self-isolated to requiring hospitalisation. If TRUE, random binomial draws at `hosp.rate`, if FALSE, random sample with a sample fraction also given by `hosp.rate.",

  "g", "disch.rand", FALSE, "Method for transition from H to R -- that is, from requiring hospitalisation to recovered. If TRUE, random binomial draws at `disch.rate`, if FALSE, random sample with a sample fraction also given by `disch.rate`. Note that the only way out of the **H** compartment is recovery or death.  ",

  "", "infection.FUN", "infection.seiqhrf.icm", "No, being infected with SARS-CoV2 is **not** fun. Rather this is the the name of the function to implement infection processes. Use the default.",

  "", "departures.FUN", "departures.seiqhrf.icm", "Handles background demographics, specifically departures (deaths not due to the virus, and emigration). Use the default.",

  "", "arrivals.FUN", "arrivals.icm", "Handles background demographics, specifically arrivals (births and immigration). Uses the original EpiModel code currently. A replacement that implements modelling the arrival of infected individuals is under development -- but for now, all arrivals go into the **S** compartment.",

  "", "get_prev.FUN", "get_prev.seiqhrf.icm", "Utility function that collects prevalence and transition time data from each run and stores it away in the simulation result object. Use the default.",

  "", "s.num", "9997", "Initial number of **S* compartment individuals in the simulated population. An overall population of 10,000 is a good compromise. A set of models will still take several minutes or more to run, in parallel. ",

  "", "e.num", "0", "Initial number of **E** compartment individuals in the simulated population.",

  "", "i.num", "3", "Initial number of **I** compartment individuals in the simulated population.",

  "", "q.num", "0", "Initial number of **Q** compartment individuals in the simulated population.",

  "", "h.num", "0", "Initial number of **H** compartment individuals in the simulated population.",

  "", "r.num", "0", "Initial number of **R** compartment individuals in the simulated population.",

  "", "f.num", "0", "Initial number of **F** compartment individuals in the simulated population.",

  "x", "act.rate.i", "10", "The number of exposure events (_acts_) between infectious individuals in the **I** compartment and susceptible individuals in the **S** compartment, per day. It's stochastic, so the rate is an average, some individuals may have more or less. Note that not every exposure event results in infection - that is governed by the `inf.prob.i` parameters (see below). Reducing `act.rate.i` is equivalent to increasing social distancing by people in the **I** compartment.",

  "x", "inf.prob.i", "0.05", "Probability of passing on infection at each exposure event for interactions between infectious people in the **I** compartment and susceptibles in **S**. Reducing `inf.prob.i` is equivalent to increasing hygiene measures, such as not putting hands in eyes, nose or moth, use of hand sanitisers, wearing masks by the infected, and so on.",

  "y", "act.rate.e", "10", "The number of exposure events (_acts_) between infectious individuals in the **E** compartment and susceptible individuals in the **S** compartment, per day. Otherwise as for `act.rate.i`.",

  "y", "inf.prob.e", "0.02", "Probability of passing on infection at each exposure event for interactions between infectious people in the **E** compartment and susceptibles in **S**. Note the default is lower than for `inf.prob.i` reflecting the reduced infectivity of infected but asymptomatic people (the **E** compartment). Otherwise as for `inf.prob.i`.",

  "z", "act.rate.q", "2.5", "The number of exposure events (_acts_) between infectious individuals in the **Q** compartment (isolated, self or otherwise) and susceptible individuals in the **S** compartment, per day. Note the much lower rate than for the **I** and **E** compartments, reflecting the much greater degree of social isolation for someone in (self-)isolation. The exposure event rate is not zero for this group, just much less. Otherwise as for `act.rate.i`.",

  "z", "inf.prob.q", "0.02", "Probability of passing on infection at each exposure event for interactions between infectious people in the **Q** compartment and susceptibles in **S**. Note the default is lower than for `inf.prob.i` reflecting the greater care that self-isolated individuals will, on average, take regarding hygiene measures, such as wearing masks, to limit spread to others. Otherwise as for `inf.prob.i`.",

  "c", "quar.rate", "1/30", "Rate per day at which symptomatic (or tested positive), infected **I** compartment people enter self-isolation (**Q** compartment). Asymptomatic **E** compartment people can't enter self-isolation because they don't yet know they are infected. Default is a low rate reflecting low community awareness or compliance with self-isolation requirements or practices, but this can be tweaked when exploring scenarios.",

  "e,i", "hosp.rate", "1/100", "Rate **per day** at which symptomatic (or tested positive), infected **I** compartment people or self-isolated **Q** compartment people enter the state of requiring hospital care -- that is, become serious cases. A default rate of 1% per day with an average illness duration of about 10 days means a bit less than 10% of cases will require hospitalisation, which seems about right (but can be tweaked, of course).",

  "g", "disch.rate", "1/15", "Rate per day at which people needing hospitalisation recover.",

  "b", "prog.rate", "1/10", "Rate per day at which people who are infected but asymptomatic (**E** compartment) progress to becoming symptomatic (or test-positive), the **I** compartment. See `prog.rand` above for more details.",

  "b", "prog.dist.scale", "5", "Scale parameter for Weibull distribution for progression, see `prog.rand` for details.",

  "b", "prog.dist.shape", "1.5", "Shape parameter for Weibull distribution for progression, see `prog.rand` for details. Read up on the Weibull distribution before changing the default.",

  "d", "rec.rate", "1/20", "Rate per day at which people who are infected and symptomatic (**I** compartment) recover, thus entering the **R** compartment. See `rec.rand` above for more details.",

  "d", "rec.dist.scale", "35", "Scale parameter for Weibull distribution for recovery, see `rec.rand` for details.",

  "d", "rec.dist.shape", "1.5", "Shape parameter for Weibull distribution for recovery, see `rec.rand` for details. Read up on the Weibull distribution before changing the default.",

  "f", "fat.rate.base", "1/50", "Baseline mortality rate per day for people needing hospitalisation (deaths due to the virus). See `fat.rand` for more details.",

  "f", "hosp.cap", "40", "Number of available hospital beds for the modelled population. See `fat.rand` for more details.",

  "f", "fat.rate.overcap", "1/25", "Mortality rate per day for people needing hospitalisation but who can't get into hospital due to the hospitals being full (see `hosp.cap` and `fat.rand`). The default rate is twice that for those who do get into hospital.",

  "f", "fat.tcoeff", "0.5", "Time co-efficient for increasing mortality rate as time in the **H** compartment increases for each individual in it. See `fat.rand` for details.",

  "", "vital", "TRUE", "Enables demographics, that is, arrivals and departures, to and from the simulated population.",

  "", "a.rate", "(10.5/365)/1000", "Background demographic arrival rate. Currently all arrivals go into the **S** compartment, the default is approximately the daily birth rate for Australia. Will be extended to cover immigration in future versions.",

  "", "ds.rate, de.rate, de.rate, dq.rate, dh.rate, dr.rate", "various rates", "Background demographic departure (death not due to virus) rates. Defaults based on Australian crude death rates. Can be used to model emigration as well as deaths.",

  "", "out", "mean", "Summary function for the simulation runs. median is also available, or percentiles, see the `EpiModel` documentation.",
)
param_docs %>%
  gt() %>%
  fmt_markdown(columns = TRUE) %>%
  tab_options(table.width = pct(90))
```

## Time-variant parameters

Several of the simulation parameters can also be varied over time. That is, as well as accepting a single value, they also accept a vector of values with length equal to `nsteps`, the number of days over which the simulation runs. Assuming `nsteps=366`, we can, for example, set `quar.rate = c(rep(1/10,30), rep(1/3, 335))`. That defines a step function in which the transition-to-isolation rate for the **I** compartment is 0.1 for the first 30 days, then steps up to 0.33 thereafter, reflecting, say, a campaign or government edict to self-isolate. Of course, the vector of values can be a smooth function, or can go up then down again, or whatever you wish to model. This is an extremely powerful feature of computational models such as this, and one very hard to incorporate into purely mathematical models.

Most of the parameters for which time-variation is useful support it. If they don't, you will receive an error message (the table above will be updated to include this information later).

# Evidence

h = at least 15 days (>=15)
b = median 5
d = +- 2 weeks?

https://github.com/midas-network/COVID-19/tree/master/parameter_estimates/2019_novel_coronavirus

- Incubation period: 5.1 (2.2 - 11.5)
- Symptoms to death: ~15 (11 - 17)
-- So, Infection to death ~20 days
- Days to double: 3-5
-- Case report estimation is 20-30%
- Mortality rate: 1 - 1.3%?

# Baseline simulation

```{r simulation function, include=FALSE}
# function to set-up and run the baseline simulations
simulate <- function(
                     # control.icm params
                     type = "SEIQHRF",
                     nsteps = 366,
                     nsims = 8,
                     ncores = 1,
                     ages = FALSE,
                     prog.rand = FALSE,
                     rec.rand = FALSE,
                     fat.rand = TRUE,
                     quar.rand = FALSE,
                     hosp.rand = FALSE,
                     disch.rand = TRUE,
                     infection.FUN = infection.seiqhrf.icm,
                     recovery.FUN = progress.seiqhrf.icm,
                     departures.FUN = departures.seiqhrf.icm,
                     arrivals.FUN = arrivals.icm,
                     get_prev.FUN = get_prev.seiqhrf.icm,
                     # init.icm params
                     s.num = 9997,
                     e.num = 0,
                     i.num = 3,
                     q.num = 0,
                     h.num = 0,
                     r.num = 0,
                     f.num = 0,
                     # param.icm params
                     inf.prob.e = 0.02,
                     act.rate.e = 10,
                     inf.prob.i = 0.05,
                     act.rate.i = 10,
                     inf.prob.q = 0.02,
                     act.rate.q = 2.5,
                     quar.rate = 1 / 30,
                     hosp.rate = 1 / 100,
                     disch.rate = 1 / 15,
                     prog.rate = 1 / 10,
                     prog.dist.scale = 5,
                     prog.dist.shape = 1.5,
                     rec.rate = 1 / 20,
                     rec.dist.scale = 35,
                     rec.dist.shape = 1.5,
                     fat.rate.base = 1 / 50,
                     hosp.cap = 40,
                     fat.rate.overcap = 1 / 25,
                     fat.tcoeff = 0.5,
                     vital = TRUE,
                     a.rate = (10.5 / 365) / 1000,
                     a.prop.e = 0.01,
                     a.prop.i = 0.001,
                     a.prop.q = 0.01,
                     ds.rate = (7 / 365) / 1000,
                     de.rate = (7 / 365) / 1000,
                     di.rate = (7 / 365) / 1000,
                     dq.rate = (7 / 365) / 1000,
                     dh.rate = (20 / 365) / 1000,
                     dr.rate = (7 / 365) / 1000,
                     out = "mean") {
  control <- control.icm(
    type = type,
    nsteps = nsteps,
    nsims = nsims,
    ncores = ncores,
    prog.rand = prog.rand,
    rec.rand = rec.rand,
    infection.FUN = infection.FUN,
    recovery.FUN = recovery.FUN,
    arrivals.FUN = arrivals.FUN,
    departures.FUN = departures.FUN,
    get_prev.FUN = get_prev.FUN,
    verbose = TRUE,
    verbose.int = 1
  )

  init <- init.icm(
    s.num = s.num,
    e.num = e.num,
    i.num = i.num,
    q.num = q.num,
    h.num = h.num,
    r.num = r.num,
    f.num = f.num
  )

  param <- param.icm(
    inf.prob.e = inf.prob.e,
    act.rate.e = act.rate.e,
    inf.prob.i = inf.prob.i,
    act.rate.i = act.rate.i,
    inf.prob.q = inf.prob.q,
    act.rate.q = act.rate.q,
    ages = ages,
    quar.rate = quar.rate,
    hosp.rate = hosp.rate,
    disch.rate = disch.rate,
    prog.rate = prog.rate,
    prog.dist.scale = prog.dist.scale,
    prog.dist.shape = prog.dist.shape,
    rec.rate = rec.rate,
    rec.dist.scale = rec.dist.scale,
    rec.dist.shape = rec.dist.shape,
    fat.rate.base = fat.rate.base,
    hosp.cap = hosp.cap,
    fat.rate.overcap = fat.rate.overcap,
    fat.tcoeff = fat.tcoeff,
    vital = vital,
    a.rate = a.rate,
    a.prop.e = a.prop.e,
    a.prop.i = a.prop.i,
    a.prop.q = a.prop.q,
    ds.rate = ds.rate,
    de.rate = de.rate,
    di.rate = di.rate,
    dq.rate = dq.rate,
    dh.rate = dh.rate,
    dr.rate = dr.rate
  )

  sim <- icm.seiqhrf(param, init, control)
  sim_df <- as.data.frame(sim, out = out)

  return(list(sim = sim, df = sim_df))
}
```

```{r simulate, include=FALSE}

# PORDATA
pt_population <- 10260893 # 2020 est
pt_population_norte <- 3574394 # est 2019 ****** 3690681
pt_births <- 86557 # 2019
pt_deaths <- 112411 # 2019 (transparencia.sns.gov.pt)
pt_deaths_norte <- 35239 # 2018 (ine.pt)
pt_hospdeaths <- 36766 # 2019 (transparencia.sns.gov.pt)
pt_hospdeaths_norte <- 13331
pt_admissions <- 660838 # 2019 (transparencia.sns.gov.pt)
pt_admissions_norte <- 263955
pt_birthrate <- pt_births / pt_population * 1000 # 8.435621
pt_birthrate_norte <- 7.7 # ******
pt_emigrrate <- 7.9 # 2018 est
pt_deathrrate <- pt_deaths / pt_population * 1000 # 11.01766
pt_deathrrate_norte <- pt_deaths_norte / pt_population_norte * 1000 # 9.858734
pt_hdeathrrate <- pt_hospdeaths / pt_admissions * 1000 # 55.63542
pt_hdeathrrate_norte <- pt_hospdeaths_norte / pt_admissions_norte * 1000 # 50.50482
pt_hospcap <- 492000

population <- pt_population_norte
start_inf <- 3
hospcap <- pt_hospcap
birthrate <- pt_birthrate_norte
deathrate <- pt_deathrrate_norte
hdeathrrate <- pt_hdeathrrate_norte
steps <- 120

# 24 is March, 16
# 20200310 Governo estende suspensão de voos até 24 de março para todas as regiões de Itália
# 20200313 Comunicação enviada às escolas sobre suspensão das atividades com alunos nas escolas, de 16 de março a 13 de abril
# 20200313 Declaraçãoo de Situação de Alerta até 9 de abril de 2020
# 20200313 Encerramento e limitação de acesso em museus e monumentos
# 20200313 Suspensão de todas as atividades letivas e não letivas com presença de estudantes em todas as instituições de Ensino Superior
# 20200313 Interditado desembarque de passageiros e tripulantes dos navios de cruzeiro
# 20200314 Governos regionais dos Açores e da Madeira decretam colocação de passageiros chegados aos aeroportos em quarentena
# 20200314 Governos regionais dos Açores e da Madeira decretam colocação de passageiros chegados aos aeroportos em quarentena – XXII Governo – República Portuguesa
# 20200315 Restrições no acesso e na afetação dos espa‡os nos estabelecimentos comerciais e nos de restauração ou de bebidas
# 20200402 Comunicado do Conselho de Ministros de 2 de abril de 2020 – decreto que regulamenta a prorrogação do estado de emergência
# 24 is march, 16
# events <- tribble(
#   ~idx, ~dates, ~pos, ~labels,
#   16, "2020-03-08", 2, "Suspensão de visitas a lares,\nunidades de saúde e\nestabelecimentos prisionais",
#   18, "2020-03-10", 3, "Suspensão de voos de zonas\nmais afetadas de Itália",
#   19, "2020-03-11", 4, "Declaração de pandemia",
#   21, "2020-03-13", 5, "Declaração estado de alerta",
#   21, "2020-03-13", 6, "Encerramento de museus",
#   23, "2020-03-15", 7, "Restrições nos acessos\na espaços comerciais",
#   24, "2020-03-16", 8, "Suspensão das aulas",
#   24, "2020-03-16", 9, "Fecho fronteiras terrestres",
#   26, "2020-03-18", 10, "Declaração de estado\nde emergência",
#   41, "2020-04-02", 11, "Prolongamento do\nestado de emergência"
# )
# 
ages <- tribble(
  ~age, ~percent, ~severity,
    0, 0.080340751,  1,
    1, 0.103443363,  1,
    2, 0.111643592,  1,
    3, 0.123541706,  1,
    4, 0.155134254,  1,
    5, 0.153623583,  1,
    6, 0.127566805,  4,
    7, 0.08683997,   4,
    8, 0.057865975,  4
)
# 
# report_rate <- c(rep(0.25, 20), rep(0.30, steps - 20))

events <- list(
  idx = c(24, 26),
  labels = c("Fechar\nEscolas", "Estado de\nEmergência"),
  pos = c(5, 6)
)

report_rate <- c(rep(0.25, 20), rep(0.25, steps - 20))

params <- list(
  type = "SEIQHRF",
  nsteps = steps,
  nsims = 8,
  ncores = 4,

  ages = FALSE,

  # init.icm params
  s.num = population,
  e.num = 0,
  i.num = start_inf,
  q.num = 0,
  h.num = 0,
  r.num = 0,
  f.num = 0,
  # param.icm params
  act.rate.e = c(rep(15, 24), rep(6, steps - 24)), # number of exposure events between E and S. Otherwise as for act.rate.i.
  act.rate.i = c(rep(10, 24), rep(3, steps - 24)), # number of exposure events between I and S. It's stochastic, so the rate is an average, some individuals may have more or less. Reducing this parameter is equivalent to increasing social distancing by people in the I compartment.
  act.rate.q = c(rep(2.5, steps)), # number of exposure events between Q and S. Otherwise as for act.rate.i.
  inf.prob.e = 0.02, # Probability of passing on infection from E to S at each exposure event. Note the default is lower than for inf.prob.i reflecting the reduced infectivity of infected but asymptomatic people. Otherwise as for inf.prob.i
  inf.prob.i = 0.05, # Probability of passing on infection from I to S at each exposure event. Reducing inf.prob.i is equivalent to increasing hygiene measures.
  inf.prob.q = 0.02, # Probability of passing on infection from Q to S. Note the default is lower than for inf.prob.i reflecting the greater care that self-isolated individuals will, on average, take regarding hygiene measures, such as wearing masks, to limit spread to others. Otherwise as for inf.prob.i
  #############
  #############
  # weibull is preferred in this case. Weibull models a "time-to-failure" for which
  #  the failure rate is proportional to a power of time. A value of k > 1
  #  indicates that the failure rate increases with time.
  #  Median = 5 days; IQI:
  prog.rand = FALSE, # From Exposed to Infected, FALSE is Weibull, TRUE is binomial
  prog.rate = 1 / 10, # Binomial distribution, only if prog.rand is TRUE
  ##### b -> Exposed to Infected
  prog.dist.scale = 5, # Weibull distribution, only if prog.rand is FALSE
  prog.dist.shape = 1.5, # Weibull distribution, only if prog.rand is FALSE
  #############
  #############
  rec.rand = FALSE, # FALSE is Weibull, TRUE is binomial
  rec.rate = 1 / 20, # Binomial
  ####### d, g, h -> Infected, Quarantine, Hospital to Recovered
  rec.dist.scale = 35, # Weibull
  rec.dist.shape = 1.5, # Weibull
  ############
  ############ f -> H to F
  fat.rand = TRUE, # TRUE is binomial; if FALSE, random sample with a sample
  # fraction also given by fat.rate.base. However, if the current number of patients
  # in the H (needs hospitalization) compartment is above a hospital capacity level
  # specified by hosp.cap, then the fatality rate is the mean of the base fatality
  # rate weighted by the hospital capacity, plus a higher rate, specified by
  # fat.rate.overcap, weighted by the balance of those requiring hospitalization
  # (but who can't be accommodated). By setting fat.rate.overcap higher,
  # the effect of exceeding the capacity of the health care system can be simulated.
  # There is also a coefficient fat.tcoeff for the fatality rates that increases
  # them as a linear function of the number of days the individual has been in the
  # H compartment. Use of the co-efficient better approximates the trapezoid survival
  # time distribution typical of ICU patients.
  fat.rate.base = 1/100, #6.7/10000, # 2% in 30 days
  fat.rate.overcap = 1/25, #6.7/2500, # Mortality rate of those needing hospital but no capacity
  fat.tcoeff = 0.5, # Time co-efficient for increasing mortality rate as time in the H compartment increases for each individual in it.
  hosp.cap = hospcap, # 240 UCI
  #################
  #################
  quar.rand = FALSE, # if TRUE, binomial, if FALSE, random sample.
  quar.rate = 1 / 30,
  #################
  #################
  hosp.rand = FALSE, # if TRUE, binomial, if FALSE, random sample.
  hosp.rate = 1 / 100, # i, e -> I,Q to H
  #################
  #################
  disch.rand = TRUE, # If TRUE, binomial, if FALSE, random sample.
  disch.rate = 1 / 15, # g -> H to R
  #################
  #################
  # Background demographic departure (death not due to virus) rates.
  # Defaults based on Australian crude death rates.
  # Can be used to model emigration as well as deaths.
  vital = TRUE, # Enables demographics, that is, arrivals and departures, to and from the simulated population.
  # (10.5 / 365) / 1000, # Arrival rate. Default is approx the daily birth rate of Australia
  a.rate = (birthrate / 365) / 1000,
  a.prop.e = 0.01,
  a.prop.i = 0.001,
  a.prop.q = 0.01,
  ds.rate = (deathrate / 365) / 1000, # Departure rate (death not by virus)
  de.rate = (deathrate / 365) / 1000,
  di.rate = (deathrate / 365) / 1000,
  dq.rate = (deathrate / 365) / 1000,
  dh.rate = (hdeathrrate / 365) / 1000,
  dr.rate = (deathrate / 365) / 1000,
  #################
  # Summary function for the simulation runs. median is also available, or percentiles, see the EpiModel documentation.
  out = "mean"
)
```

```{r simulate2}
# load("../data/seed.rda")
#set.seed(1)
baseline_sim <- do.call("simulate", params)

sim <- baseline_sim

baseline_plot_df <- sim$df %>%
  # use only the prevalence columns
  select(time, s.num, e.num, i.num, q.num, h.num, r.num, f.num) %>%
  # examine only the first 100 days since it
  # is all over by then using the default parameters
  filter(time <= steps) %>% pivot_longer(-c(time),
    names_to = "compartment",
    values_to = "count"
  )

sim_obitos <- baseline_plot_df %>%
  filter(compartment == "f.num") %>%
  transmute(id_objeto = time, sim_obitos = count)
sim_casos <- baseline_plot_df %>%
  filter(compartment %in% c("i.num", "q.num", "h.num", "f.num", "r.num")) %>%
  group_by(time) %>%
  summarize(sim_casos = sum(count)) %>%
  ungroup() %>%
  transmute(id_objeto = time, sim_casos)
simulados <- sim_casos %>%
  left_join(sim_obitos, by = "id_objeto") %>%
  left_join(geo_norte, by = "id_objeto")

source("../R/plot_sir.R", encoding = "UTF-8")

plot_sir(simulados, report_rate, events, 40)
```

Several of the simulation parameters can also be varied over time. That is, as well as accepting a single value, they also accept a vector of values with length equal to nsteps, the number of days over which the simulation runs. Assuming nsteps=366, we can, for example, set quar.rate = c(rep(1/10,30), rep(1/3, 335)). That defines a step function in which the transition-to-isolation rate for the I compartment is 0.1 for the first 30 days, then steps up to 0.33 thereafter, reflecting, say, a campaign or government edict to self-isolate. Of course, the vector of values can be a smooth function, or can go up then down again, or whatever you wish to model. This is an extremely powerful feature of computational models such as this, and one very hard to incorporate into purely mathematical models.

Most of the parameters for which time-variation is useful support it. If they don’t, you will receive an error message (the table above will be updated to include this information later).

## Distribution of duration in key compartments

```{r get times, echo=FALSE, fig.height=12, fig.width=8, warning=FALSE}
# define a function to extract timings and assemble a data frame
get_times <- function(simulate_results) {
  sim <- simulate_results$sim

  for (s in 1:sim$control$nsims) {
    if (s == 1) {
      times <- sim$times[[paste("sim", s, sep = "")]]
      times <- times %>% mutate(s = s)
    } else {
      times <- times %>%
        bind_rows(sim$times[[paste("sim", s, sep = "")]] %>%
          mutate(s = s))
    }
  }

  times <- times %>%
    mutate(
      infTime = ifelse(infTime < 0, -5, infTime),
      expTime = ifelse(expTime < 0, -5, expTime)
    ) %>%
    mutate(
      incubation_period = infTime - expTime,
      illness_duration = recovTime - expTime,
      illness_duration_hosp = dischTime - expTime,
      hosp_los = dischTime - hospTime,
      quarantine_delay = quarTime - infTime,
      survival_time = fatTime - infTime
    ) %>%
    select(
      s,
      incubation_period,
      quarantine_delay,
      illness_duration,
      illness_duration_hosp,
      hosp_los,
      survival_time
    ) %>%
    pivot_longer(-s,
      names_to = "period_type",
      values_to = "duration"
    ) %>%
    mutate(period_type = factor(period_type,
      levels = c(
        "incubation_period",
        "quarantine_delay",
        "illness_duration",
        "illness_duration_hosp",
        "hosp_los",
        "survival_time"
      ),
      labels = c(
        "Incubation period",
        "Delay entering isolation",
        "Illness duration",
        "Illness duration (hosp)",
        "Hospital care required duration",
        "Survival time of case fatalities"
      ),
      ordered = TRUE
    ))
  return(times)
}

times <- get_times(baseline_sim)

times %>%
  filter(duration <= 30) %>%
  ggplot(aes(x = duration)) +
  geom_bar() +
  facet_grid(period_type ~ ., scales = "free_y") +
  labs(
    title = "Duration frequency distributions",
    subtitle = "Baseline simulation"
  )
```
OK, all of those distributions of the time spent in the various states (compartments) look reasonable, with the exception of _Hospital care required duration_. For quite a few individuals, that duration is zero. You could argue that these are day-only admissions, but really, hospital care should be required for at least one day. It's something that can be fixed later, but it makes little difference for now.

## Baseline Prevalence

### Overall

```{r baseline plot, echo=FALSE, fig.height=5, fig.width=10, warning=FALSE}
# define a standard set of colours to represent compartments
compcols <- c(
  "s.num" = "yellow", "e.num" = "orange", "i.num" = "red",
  "q.num" = "cyan", "h.num" = "magenta", "r.num" = "lightgreen",
  "f.num" = "black"
)
complabels <- c(
  "s.num" = "Suscetíveis", "e.num" = "Infetados/Assintomáticos",
  "i.num" = "Infetados/Sintomáticos", "q.num" = "Em Quarentena",
  "h.num" = "Casos Graves", "r.num" = "Recuperados",
  "f.num" = "Óbitos"
)
baseline_plot_df %>%
  ggplot(aes(x = time, y = count, colour = compartment)) +
  geom_line(size = 1, alpha = 0.7) +
  scale_colour_manual(values = compcols, labels = complabels) +
  theme_dark() +
  labs(
    title = "Simulação Inicial - Zona Norte",
    x = "Dias desde o início da epidemia",
    y = "Prevalência (pessoas)"
  ) +
  scale_y_continuous(labels = scales::comma)
```

### Zoom in

```{r baseline zoom, echo=FALSE, fig.height=5, fig.width=10, warning=FALSE}
baseline_plot_df %>%
  filter(compartment %in% c(
    # "e.num", "i.num",
    # "q.num",
    "h.num",
    "f.num"
  )) %>% # filter(time <= 37) %>%
  ggplot(aes(x = time, y = count, colour = compartment)) +
  geom_line(size = 1, alpha = 0.7) +
  scale_colour_manual(values = compcols, labels = complabels) +
  theme_dark() +
  labs(
    title = "Simulação Inicial - Zona Norte",
    x = "Dias desde o início da epidemia",
    y = "Prevalência (pessoas)"
  ) +
  scale_y_continuous(labels = scales::comma)
```
### Basic reproduction number $R_{0}$

```{r baseline R0, echo=FALSE, fig.height=5, fig.width=10, warning=FALSE}
# get the S-> E compartment flow, which is
# our daily incidence rate
incidence_counts <- baseline_sim$df %>%
  select(time, se.flow)
# uncount them
incident_case_dates <- incidence_counts %>%
  uncount(se.flow) %>%
  pull(time)
# convert to an incidence object
incidence_all <- incident_case_dates %>%
  incidence(.)

# plot the incidence curve
plot(incidence_all)
```

```{r message=FALSE, warning=FALSE}
# find the peak of the epidemic curve
peak_of_epidemic_curve <- find_peak(incidence_all)

# repeat with just the growth part of the epidemic curve
incident_case_dates_growth_phase <- incidence_counts %>%
  filter(time <= peak_of_epidemic_curve) %>%
  select(time, se.flow) %>%
  uncount(se.flow) %>%
  pull(time)

incidence_growth_phase <- incident_case_dates_growth_phase %>%
  incidence(., last_date = peak_of_epidemic_curve)
# specify serial interval mean and SD
# since the last blog post new studies have appeared
# suggesting 4.5 is a better mean for the SI
si_mean <- 4.5
si_sd <- 3.4

# get a set of MLE estimates for R0 and plot
res <- get_R(incidence_growth_phase, si_mean = si_mean, si_sd = si_sd)
plot(res, "R")
```

# Running an intervention experiment














# Other topics to review

```{r icm_model}
# running 100 days, 10 times
control <- control.icm(type = "SIR", nsteps = 100, nsims = 10)

# susceptible 997, infected 3
init <- init.icm(s.num = 997, i.num = 3, r.num = 0)

# These parameters needs to be tweaked:
# - rate of exposure (act.rate): 10
# - probability of infection at each exposure (inf.prob): 0.05
# - recovery rate (rec.rate): 1/20
# - arrival rate (a.rate): (10.5/365)/1000
# - deaths or emigration (ds, di, dr.rate): (7/365)/1000, (3.5/365)/1000, (7/365)/1000
param <- param.icm(
  inf.prob = 0.05, act.rate = 10, rec.rate = 1 / 20, a.rate = (10.5 / 365) / 1000,
  ds.rate = (7 / 365) / 1000, di.rate = (3.5 / 365) / 1000,
  dr.rate = (7 / 365) / 1000
)

# Run the simulation
sim <- icm(param, init, control)
```
```{r icm_model_plot}
sim
plot(sim, main = "SIR Model")
plot(sim, y = "si.flow", mean.col = "red", qnts.col = "red", main = "Incidence")
```

## Exploring public health interventions using the ICM SIR model

### Avoiding exposure with social distancing

- TODO: Change the act.rate
- TODO: use different rates with sub-groups

### Basic hygiene measures

- TODO: Change the inf.prob
- TODO: sub-groups?

565 -> screened for symptoms and tested for nCOV
63 -> had symptoms
8 -> had the virus
3/8 -> had symptoms

     beta     gamma 
0.6671730 0.3328275 

      R0 
2.004561 

- TODO: Estimar Re: instantaneous effective reproduction number
"We’ll treat the initial 41 cases as “imported”, possibly from a different species at the Wuhan fish markets."
A critical parameter for the Cori model is the serial interval (SI). The SI is the time between onset of symptoms of each case of the disease in question, and the onset of symptoms in any secondary cases that result from transmission from the primary cases. In other words, it is the time between cases in the (branching) chain of transmission of the disease. 

 A moment’s reflection reveals that the SI is, in fact, a statistical distribution of serial interval times, rather than a fixed value. That distribution can be simulated, typically using a discrete gamma distribution with a given mean and standard deviation.
 
The estimate_R() function in the EpiEstim package allows the SI distribution to be specified parametrically. It also allows uncertainty to be incorporated into the parameterisation of this distribution, and it even allows the SI distribution to be estimated empirically, using Bayesian methods, from individual line-listings of cases. We’ll examine all of those capabilities.
## 

At the time of writing, I was able to find only one published estimate of the serial interval distribution, derived from analysis of just 5 primary cases amongst the first 450 cases in Wuhan, published by Li et al.. They estimate the serial interval distribution to have a mean of 7.5 days with a standard deviation of 3.4 days. This is almost identical to the serial interval parameters for the MERS virus, which were a mean of 7.6 and a SD of 3.4. This similarity is not surprising given that both pathogens are coronavirii. Let’s use that to estimate the instantaneous Re for Hubei province.

Data limitations
The biggest problem with these analyses is that they are not based on data tabulated by date of onset (of symptoms), but rather on data tabulated by date of reporting, or perhaps date of confirmation by lab test. If lab testing and reporting is swift and the lag is uniform, then the date of reporting or confirmation will lag consistently and only slightly behind the date of onset. But reality is rarely so nice, and typically there are variable delays in lab confirmation and/or reporting, leading to backlogs of cases being reported all at once (known as a “data dump” by outbreak epidemiologists). This is very unfortunate, and it frustrates efforts to properly assess outbreak trajectories and effectiveness of intervention strategies. The solution is for authorities to provide line-listings of all cases, including their date of reporting and their date of onset of symptoms, even if only presumptive dates are provided (and missing dates of onset can be imputed, in any case). No details that permit identification of cases or invasion of their privacy need be provided in such line listings.

```{r Exploring the intervention}
# For now, just a copy-paste from Tim's blog

run_sir_sim <- function(inf_prob, act_rate, pop_size = 1000,
                        i_num = 3, n_steps = 365, n_sims = 10, si_mean = 7.5, si_sd = 3.4) {

  # set up simulation parameters
  param <- param.icm(
    inf.prob = inf_prob, act.rate = act_rate,
    rec.rate = 1 / 20, a.rate = (10.5 / 365) / 1000, ds.rate = (7 / 365) / 1000,
    di.rate = (3.5 / 365) / 1000, dr.rate = (7 / 365) / 1000
  )
  init <- init.icm(
    s.num = pop_size - i_num, i.num = i_num,
    r.num = 0
  )
  control <- control.icm(type = "SIR", nsteps = n_steps, nsims = n_sims, verbose.int = 1, verbose = TRUE)

  # run the simulation
  sim <- icm(param, init, control)

  # collect the relevant results in a data frame
  incidence_rates <- as.data.frame(sim, out = "mean") %>%
    select(
      time,
      si.flow, i.num
    ) %>%
    mutate(
      act_rate = act_rate, inf_prob = inf_prob,
      total_cases = sum(si.flow), max_prev = max(i.num, na.rm = TRUE)
    )

  # use the data frame of results to create an incidence()
  # object
  local_case_dates <- incidence_rates %>%
    filter(
      time <= 300,
      act.rate == act_rate, inf.prob == inf_prob
    ) %>%
    select(
      time,
      si.flow
    ) %>%
    uncount(si.flow) %>%
    pull(time)

  if (length(local_case_dates) > 0) {
    local_cases <- local_case_dates %>% incidence(.)

    # find the incidence peak from the incidence object
    peaky_blinder <- find_peak(local_cases)

    # recreate the incidence object using data only up to the
    # peak
    local_growth_phase_case_dates <- incidence_rates %>%
      filter(time <= peaky_blinder) %>%
      select(time, si.flow) %>%
      uncount(si.flow) %>%
      pull(time)

    local_growth_phase_cases <- local_growth_phase_case_dates %>%
      incidence(., last_date = peaky_blinder)

    # get a MLE estimate of the basic reproduction number, R0
    res <- get_R(local_growth_phase_cases,
      si_mean = si_mean,
      si_sd = si_sd
    )

    # add that as a column to the data frame of results
    incidence_rates <- incidence_rates %>% mutate(mle_R0 = res$R_ml)
  } else {
    # can't calculate R0 so just set to NA
    incidence_rates <- incidence_rates %>% mutate(mle_R0 = NA)
  }
  # return the data frame (which has just one row)
  return(incidence_rates)
} # end function definition
```
```{r interventions_sims}
# set up an empty data frame to which to append results from
# each simulation
sims_incidence_rates <- tibble(
  time = integer(0), si.flow = numeric(0),
  i.num = numeric(0), act_rate = numeric(0), inf_prob = numeric(0),
  total_cases = numeric(0), max_prev = numeric(0), mle_R0 = numeric(0)
)

# the parameters to step through
# act.rates <- c(10, 5, 2)
# inf.probs <- c(0.05, 0.025, 0.01)
act.rates <- c(10)
inf.probs <- c(0.05)

# loop through the parameter space
for (act.rate in act.rates) {
  for (inf.prob in inf.probs) {
    sims_incidence_rates <- sims_incidence_rates %>% bind_rows(run_sir_sim(
      inf.prob,
      act.rate
    ))
  }
}
```
```{r plot_sims}
# create facet columns as descending ordered factors
sims_incidence_rates <- sims_incidence_rates %>%
  mutate(act_rate_facet_label = paste(
    act_rate,
    "exposures per day"
  ), inf_prob_facet_label = paste(
    "Probability of infection\nat each exposure:",
    inf_prob
  )) %>%
  arrange(desc(act_rate)) %>%
  mutate_at(
    vars(act_rate_facet_label),
    list(~ factor(., levels = unique(.)))
  ) %>%
  arrange(desc(inf_prob)) %>%
  mutate_at(vars(inf_prob_facet_label), list(~ factor(., levels = unique(.)))) %>%
  arrange(desc(act_rate), desc(inf_prob), time)

# add annotation text for each facet
sims_incidence_rates_facet_annotations <- sims_incidence_rates %>%
  mutate(label = paste(
    "R0 =", format(mle_R0, digits = 3),
    "\n", round(100 * total_cases / 1000, digits = 0), "% of population infected"
  )) %>%
  select(inf_prob_facet_label, act_rate_facet_label, label) %>%
  distinct()

sims_incidence_rates %>%
  filter(time <= 365) %>%
  ggplot(aes(
    x = time,
    y = si.flow
  )) +
  geom_line(colour = "blue", size = 1.5) +
  facet_grid(inf_prob_facet_label ~ act_rate_facet_label) +
  geom_text(
    data = sims_incidence_rates_facet_annotations,
    mapping = aes(x = 50, y = 0.8 * max(sims_incidence_rates$si.flow,
      na.rm = TRUE
    ), label = label), parse = FALSE, hjust = 0,
    vjust = 0, size = 3
  ) +
  labs(
    x = "Days since start of epidemic",
    y = "New cases per day", title = "Modelling of new cases of COVID-19 per day: incidence rate",
    subtitle = paste(
      "with varying levels of social mixing (exposures per day)",
      "and probabilities of infection at each exposure"
    )
  ) +
  theme(legend.position = "top", strip.text = element_text(size = 14))
```
```{r plot_incidences}
# create one column for both intervention parameters
sims_incidence_rates <- sims_incidence_rates %>%
  mutate(intervention_level_label = paste(
    act_rate,
    "exp/day,", inf_prob * 100, "% inf risk/exp"
  )) %>%
  arrange(
    max_prev,
    time
  ) %>%
  mutate_at(vars(intervention_level_label), list(~ factor(.,
    levels = unique(.), ordered = TRUE
  )))

sims_incidence_rates %>%
  filter(time <= 365) %>%
  ggplot(aes(
    x = time,
    y = intervention_level_label, height = i.num, fill = intervention_level_label
  )) +
  geom_density_ridges(stat = "identity", show.legend = FALSE) +
  labs(
    x = "Days since start of epidemic", y = "Prevalent (current number of active) cases",
    title = "Modelling of COVID-19 transmission in 1,000 simulated people",
    subtitle = paste(
      "with varying levels of social mixing (exposures per day)",
      "and risk of infection at each exposure,\n", "ordered by descending maximum number of prevalent cases per day"
    )
  ) +
  theme_minimal() +
  theme(legend.position = "top", strip.text = element_text(size = 12)) +
  scale_fill_brewer(type = "seq", palette = "Oranges")
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.


## Data We Need

Nishiura et al. (https://www.mdpi.com/2077-0383/9/2/419)
565 -> screened for symptoms and tested for nCOV
63 -> had symptoms
8 -> had the virus
3/8 -> had symptoms

- Portugal Health-care capacity?
- Ascertainment rates?
- Time between Case0 symptoms and Case1 symptoms

# References
